{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Enunciado_T2.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0Y1tHj3DNqhX"},"source":["<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n","\n","\n","<hr style=\"height:2px;border:none\"/>\n","<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n","\n","<H3 align='center'> Tarea 2 - Aplicaciones Recientes de Redes Neuronales </H3>\n","\n","<H2 align='center'> Pregunta 2.Encoder-Decoder sobre imágenes</H2>\n","<H3 align='center'> Francisca Ramírez</H3>\n","<H3 align='center'> Sebastian Ramírez</H3>\n","\n","<hr style=\"height:2px;border:none\"/>\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iFtCUBp9Nqhb"},"source":["<a id=\"segundo\"></a>\n","## 2. Encoder-Decoder sobre imágenes\n","---\n","En la presente seccion se experimentará con arquitecturas del tipo *encoder-decoder* [[3]](#refs) aplicadas sobre imágenes, tales como *image translation*, *object location*, *image segmentation*, entre otros. La idea es aplicar una red convolucional en ambas partes del modelo (encoder y decoder), así utilizamos un modelo que se adapte a estos casos.\n","\n","La tarea consistirá en realizar **Image Segmentation** [[4]](#refs) para identificar ciertos segmentos o regiones de interés en una imagen a través de procesar de manera semántica (en la codificación) si cada pixel corresponde a un segmento a destacar. Esta tarea puede ser aplicada tanto para identificar un segmento como para identificar múltiples segmentos a través de colocar varios canales/filtros de salida en el *decoder*. Para ésto trabajaremos con un dataset creado en el área (*A BENCHMARK FOR SEMANTIC IMAGE SEGMENTATION*). El dataset resulta bastante pequeño en cantidad de datos, por lo que deberá pensar en formas de conllevar ésto.\n","\n","<img src=\"https://qph.fs.quoracdn.net/main-qimg-78a617ec1de942814c3d23dab7de0b24\" width=\"70%\" />\n","\n","Descargue los datos a través del siguiente __[link](http://www.ntu.edu.sg/home/ASJFCai/Benchmark_Website/benchmark_index.html)__. Luego cargue las pocas imágenes a trabajar con la librería __[Pillow](pillow.readthedocs.io)__. Debido a la dimensionalidad variable de los datos de entrada deberá redimensionar a un valor que considere prudente, *se aconseja menos de 250*, comente su decisión.\n","```python\n","import numpy as np\n","import os\n","img_size = choose\n","folder = \"imagefolder..\"\n","data = [archivo.split(\".\")[0] for archivo in os.listdir(folder+\"/image\")]\n","from PIL import Image\n","X_image = []\n","for archivo in data:\n","    I = Image.open(folder+\"/image/\"+archivo+\".jpg\")\n","    I = np.asarray(I.resize( (img_size,img_size),Image.ANTIALIAS ))\n","    X_image.append(I)\n","X_image = np.asarray(X_image)\n","Y_image = []\n","for archivo in data:\n","    I = Image.open(folder+\"/ground-truth/\"+archivo+\".png\")\n","    I = np.asarray(I.resize( (img_size,img_size),Image.ANTIALIAS ))\n","    Y_image.append(I)\n","Y_image = np.asarray(Y_image)\n","```\n","\n","> a) Explore los datos a trabajar, visualice la entrada y salida del modelo, además de las dimensionalidades de éstas ¿Es un problema las dimensiones de los datos *versus* la cantidad de datos a entrenar? Normalice los datos como se acostumbra en imágenes y genere una dimensión/canal extra a la salida.\n","```python\n","...#visualize and do nice plots!\n","X_image = X_image/255.\n","Y_image = Y_image/255.\n","Y_image = Y_image[:,:,:,None]\n","```\n","\n","> b) Separe 10 imágenes como conjunto de pruebas para verificar la calidad del modelo entrenado.\n","\n","> c) Debido a la poca cantidad de datos presentes defina la arquitectura a utilizando únicamente convolucionales (*fully convolutional*) [[5]](#refs), como la presente en el código. Comente sobre los cambios en la dimensionalidad a través del *forward pass*. Decida el tamaño del *batch* en base a la cantidad de datos que se presenta para entrenar.\n","```python\n","from keras.models import Sequential\n","from keras.layers import Conv2D,MaxPool2D, Conv2DTranspose, UpSampling2D, BatchNormalization\n","model = Sequential()\n","...#ENCODER PART\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='same',input_shape=X_image.shape[1:]))\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPool2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPool2D((2, 2)))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","...#DECODER PART\n","model.add(UpSampling2D((2, 2)))\n","model.add(Conv2DTranspose(32, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2DTranspose(32, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2DTranspose(1, (3, 3), strides=(2,2), activation='sigmoid', padding='same')) #pixel-wise classification\n","model.summary()\n","model.compile(loss='binary_crossentropy',optimizer='rmsprop')\n","model.fit(X_train,Y_train,epochs=100,batch_size=...)\n","```\n","\n","> d) Para medir el desempeño del modelo sobre ambos conjuntos realice un análisis cualitativo en base a visualizar la segmentación que realiza *versus* la segmentación real, además de verificar el *precision* y *recall* asumiendo valores binarios de pixel ¿Qué valor debería ser más importante los ceros o 1? Comente.\n","```python\n","Y_hat_train = np.squeeze( model.predict(X_train) )\n","Y_hat_test = np.squeeze( model.predict(X_test) )\n","...#visualice Y_hat and Y_image\n","from sklearn.metrics import precision_score, recall_score\n","Y_label = Y_train.flatten() >0.5\n","Y_hat_label = Y_hat_train.flatten() >0.5\n","print(precision_score(Y_label, Y_hat_label, average=None, labels=[0,1] ))\n","print(recall_score(Y_label, Y_hat_label, average=None , labels=[0,1]))\n","```\n","\n","> e) Compárese con alguna técnica manual de *Image Segmentation*, comúnmente se sugiere considerar un *treshold* para activar o apagar un píxel. Experimente con utilizar *treshold* igual a la media o con otra técnica más inteligente basada en los histogramas de escala de grises, como se utilizan en *skimage*.\n","```python\n","gray_X = 0.2125*X_image[:,:,:,0]+ 0.7154*X_image[:,:,:,1]+ 0.0721*X_image[:,:,:,2] #needed gray-scale\n","...\n","\"\"\" One option\"\"\"\n","val = gray_X.mean()  #or another statistical\n","\"\"\" Another option\"\"\"\n","from skimage import filters\n","val = filters.threshold_otsu(gray_X)\n","... \n","mask = gray_X < val\n","X_segmented = mask*1\n","```\n","\n","> f) Experimente con realizar *data augmentation* sobre el problema. Debido a que las operaciones clásicas de *augmentation* como rotar, invertir, girar, cambiarian la etiqueta de segmentación, genere una estrategia que mantenga la etiqueta/salida $Y$. Se presenta un código de ejemplo, *Denoising*, de aplicar una máscara binaria aleatoria sobre la imagen de entrada $X$, **de todas formas se espera que proponga alguna distinta**. Compare el desempeño alcanzado con la nueva red con la forma de evaluar definida en (d).\n","```python\n","from numpy.random import binomial #DENOISING IDEA\n","T = 100\n","for _ in range(T):\n","    noise_level = np.random.randint(4,10)/10.\n","    noise_mask = binomial(n=1,p=noise_level,size=X_image.shape)\n","    X_augmented = X_image*noise_mask\n","    model.fit(X_augmented,Y_image,epochs=1,batch_size=32,validation_data=(X_image,Y_image))\n","```\n","\n","> g) Intente variar la arquitectura presentada en pos de obtener un mejor modelo, basado en la evaluación realizada en (d). Recuerde tomar en cuenta la poca cantidad de datos que se tiene."]}]}